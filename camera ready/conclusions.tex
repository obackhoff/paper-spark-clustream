We proposed a variation of \emph{CluStream} tailored to Apache Spark, \our.
Our experiments show that~\our~achieves similar quality to the original approach~\cite{clustreamOrig}, while it is far more efficient.
% Also, \our~outperforms existing stream clustering implementations in SPARK.
Comparing to other stream clustering approaches in Spark, our results show that \textit{Streaming K-Means} is the fastest algorithm among the three tested (highly optimized for Spark), but it does not offer the flexibility of the online-offline clustering approaches like \textit{CluStream} that better fit evolving data streams. 
Comparing \our~to \huawei, \our~delivers more consistent and accurate results, and outperforms \huawei in most cases, including one up to around 18 times faster. 

% Our~\our~on the other hand does not only deliver qualitative clustering results, but also outperforms \textit{StreamDM}, another \emph{CluStream} implementation. 
% Quality-wise it delivered more consistent and accurate results, and performance-wise it outperformed it in most cases, including one up to around 18 times faster. 
As part of our future work, we will focus on minimizing the communication cost between the different nodes to further improve the efficiency and also on dealing with outliers to improve quality.

% Bringing successfully the \textit{CluStream} method to Spark has provided valuable information about how similar methods could be adapted by reviewing some of the challenges which might occur. It has also provided deep understanding of this method itself and how stream clustering differs from other clustering methods, which might not need to adapt to changing data, of Apache Spark and how distributed systems work in general, but most importantly it has provided the experience to parallelize algorithms for the specific requirements of a given problem and this knowledge itself is applicable to an uncountable number of problems.


% \subsection{Goals achieved}

% It is rewarding to conclude that the goals were met satisfactorily. Here, the conclusions for every one of them.

% \subsubsection{Adapt \textit{CluStream} in Spark (Spark-CluStream)}

% This is the main goal of this thesis, and none of the other goals would have been met if this one failed. Adapting \textit{CluStream} in Spark brought many challenges: one being the fact that the streaming library in Spark handles streams as batches and not individual points with time stamps, forcing this adaptation to change a few things that differentiate it from the original method, and the other one being the parallelization of the algorithm in order to take advantage of distributed computing.

% Even though this adaptation changed the way data is processed, i.e. processing the stream in batches of data in parallel as much as possible, the results indicate that this was done correctly: it showed that it is not only capable of correctly clustering streams of data but it was able to match the quality of the original method described in \cite{clustreamOrig}. It was shown for two different scenarios that this is true, when comparing the errors obtained after replicating the tests done by the authors of \textit{CluStream}.

% \subsubsection{Understanding its advantages and disadvantages}

% The second most important goal was to make this adaptation as scalable as possible, and for this reason many tests were made using different scenarios. There are clearly cases where it is not fully scalable, but for the most part it was shown comparable scalability as some of the alternatives for Spark, including a method native of Spark and a similar method developed by a team from \textit{Huawei} for a set of stream mining algorithms called \textit{StreamDM}.

% Some of its limitations were also understood , such as bottlenecks that might reduce the scalability and performance in general, such as:

% \begin{itemize}
%  \item Outliers: handling with outliers in sequential code is expected to be a bottleneck, depending on the stream, a batch of data might contain points which do not belong to any micro-cluster and therefore, they have to be handled differently. Depending on the number of outliers, in particular the ones which require two micro-clusters to be merged, the total processing time for that batch will be affected negatively. In general there are three situations where this would normally occur: at the beginning of the stream if the initialization is not accurate, when the incoming data is very noisy and when the data dramatically changes.
%  \item Communication costs: running in parallel requires certain communication between processing units. This affects the scalability negatively when few computations are required and too many processing units are used, as most of the time will be spent on communication. Also, even when it is expected to be scalable, increasing the number of micro-clusters used and the dimensionality of the data results in a bigger amount of information to communicate, and therefore not allowing greater speedups after a certain amount of processing units. 
% \end{itemize}
